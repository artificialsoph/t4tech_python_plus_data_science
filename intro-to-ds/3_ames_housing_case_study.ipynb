{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Prices - A case study with SciKit Learn and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a module in Python that is great for handling lots of data. We'll be relying on it today to help us sort, reshape, and clean up our data. \n",
    "\n",
    "> **From the Pandas documentation:**\n",
    ">\n",
    "> Here are just a few of the things that pandas does well:\n",
    ">\n",
    "> - Easy handling of **missing data** (represented as NaN) in floating point as well as non-floating point data\n",
    "- Size mutability: columns can be **inserted and deleted** from DataFrame and higher dimensional objects\n",
    "- Automatic and explicit **data alignment**: objects can be explicitly aligned to a set of labels, or the user can simply ignore the labels and let Series, DataFrame, etc. automatically align the data for you in computations\n",
    "- Powerful, flexible **group by** functionality to perform split-apply-combine operations on data sets, for both aggregating and transforming data\n",
    "- Make it **easy to convert** ragged, differently-indexed data in other Python and NumPy data structures into DataFrame objects\n",
    "- Intelligent **label-based slicing**, **fancy indexing**, and **subsetting** of large data sets\n",
    "- Intuitive **merging** and **joining** data sets\n",
    "- Flexible **reshaping** and **pivoting** of data sets\n",
    "- **Hierarchical labeling** of axes (possible to have multiple labels per tick)\n",
    "- **Robust IO tools** for loading data from flat files (CSV and delimited), Excel files, databases, and saving / loading data from the ultrafast HDF5 format\n",
    "- **Time series**-specific functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc.\n",
    "\n",
    "Let's get a sense of how it works with a test data set from a weather report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.655235Z",
     "start_time": "2017-12-04T20:49:47.379992Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # the pd is by convention\n",
    "import numpy as np # as is the np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To Plot matplotlib figures inline on the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building blocks of pandas are called Series and DataFrames. A Dataframe is essentially a table, like shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/dataframe.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the dataframe will be one specific record, and each column will be some aspect of that record. That will make more sense when we look at an example. Series are individual rows or columns (essentially if we break apart that dataframe into a single set of numbers). Let's look at that in action.\n",
    "\n",
    "To begin with, we're going to read in some data from a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.710748Z",
     "start_time": "2017-12-04T20:49:48.658767Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/weather.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got our table, and it shows us that we're looking at the hourly weather at some point. We can see that the temperature was below freezing for each of the first four hours, that there was some fog, and that it was a little bit windy. We used `weather.head()` to show us just the first few rows. Otherwise, it would show us a HUGE data amount. We can look at the last few rows with `weather.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.736073Z",
     "start_time": "2017-12-04T20:49:48.716462Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use a Pandas built-in function to learn a little about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.753570Z",
     "start_time": "2017-12-04T20:49:48.739693Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look to see how much of our data makes sense by asking it to look at the numeric columns and give us some stats about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.791570Z",
     "start_time": "2017-12-04T20:49:48.759670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.801500Z",
     "start_time": "2017-12-04T20:49:48.794923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, looks like these are all behaving relatively as expected! That's lovely. Now let's learn how to grab some data from the DataFrame. Also, let's look at what a Series is. To start with, let's grab a column from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.815906Z",
     "start_time": "2017-12-04T20:49:48.805937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['Temp (C)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a series! It has both the index (the left side) and the value. So we know which row it is and what the value is. That's pretty sweet. What can we do with a series? One really handy thing is getting the number of times a value shows up. Let's see that in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.830592Z",
     "start_time": "2017-12-04T20:49:48.819297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['Weather'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Now how do we access rows? We have to play a little bit of pandas games to do so. We'll use `.iloc` to do the job. Let's demonstrate by grabbing the first (0th) row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.845536Z",
     "start_time": "2017-12-04T20:49:48.833705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get multiple rows by following Python's conventions like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.868718Z",
     "start_time": "2017-12-04T20:49:48.849262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.iloc[10:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also might want to select multiple columns. We can do that like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.887740Z",
     "start_time": "2017-12-04T20:49:48.872039Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather[['Temp (C)',\"Dew Point Temp (C)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be enough to get us started with Pandas... now let's move on to our case study, and we'll learn more about Pandas on the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Building Regression Models with Scikit-Learn\n",
    "\n",
    "In this section, we will walk through how to build regression models in scikit-learn.\n",
    "\n",
    "We will load in a the Ames Housing Data, split into train and test sets, and build some models.\n",
    "\n",
    "Using the Ames Housing Data:\n",
    "\n",
    "Dean De Cock\n",
    "Truman State University\n",
    "Journal of Statistics Education Volume 19, Number 3(2011), www.amstat.org/publications/jse/v19n3/decock.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.896685Z",
     "start_time": "2017-12-04T20:49:48.891091Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "datafile = \"./data/Ames_Housing_Data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.948609Z",
     "start_time": "2017-12-04T20:49:48.901024Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(datafile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:48.981808Z",
     "start_time": "2017-12-04T20:49:48.952754Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Data Dictionary\n",
    "A description of the variables can be found here:\n",
    "\n",
    "https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Data Cleaning\n",
    "From the above, and reading the documentation, here are a few things to note about this data set:\n",
    "- SalePrice is our target variable\n",
    "- The authors recommend removing the few houses that are >4000 SQFT (based on the 'Gr Liv Area' variable)\n",
    "- Many columns have missing data (based on the number of \"non-null\" entries in each column\n",
    "- We have many predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** An aside about pandas **\n",
    "\n",
    "We can do filtering on the fly with pandas. Let's see what that means by looking at our weather data from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.006122Z",
     "start_time": "2017-12-04T20:49:48.984631Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_test = weather[weather['Temp (C)'] == -1.8]\n",
    "weather_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can can pandas to only show us rows where some condition is true. In this case, we asked to only show when the temerature was -1.8 degrees Celsius. We can do the same type of thing with any conditions!\n",
    "\n",
    "Now back to the housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Remove all houses that are greater than 4000 sqft with filtering (‘Gr Liv Area’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- How many data points did we remove from the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.014189Z",
     "start_time": "2017-12-04T20:49:49.009471Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Next, let's restrict ourselves to just a few variables to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.026895Z",
     "start_time": "2017-12-04T20:49:49.019591Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "smaller_df= df[['Lot Area','Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add',\n",
    "        'Gr Liv Area', \n",
    "        'Full Bath', 'Bedroom AbvGr',\n",
    "        'Fireplaces', 'Garage Cars','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.129610Z",
     "start_time": "2017-12-04T20:49:49.029344Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Let's have a look at these variables\n",
    "\n",
    "smaller_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.146989Z",
     "start_time": "2017-12-04T20:49:49.132669Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "smaller_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.154830Z",
     "start_time": "2017-12-04T20:49:49.149743Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# There appears to be one NA in Garage Cars - fill with 0\n",
    "smaller_df = smaller_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:49:49.172325Z",
     "start_time": "2017-12-04T20:49:49.157818Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "smaller_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.708729Z",
     "start_time": "2017-12-04T20:49:49.175689Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Let's do a pairplot with seaborn to get a sense of the variables in this data set\n",
    "sns.pairplot(smaller_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Comprehension question\n",
    "From the pairplot above:\n",
    "\n",
    "- Which variables seem to have the strongest correlations with SalePrice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.717794Z",
     "start_time": "2017-12-04T20:50:04.710828Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's make a X and y for our predictors and target, respectively\n",
    "\n",
    "X=smaller_df[['Lot Area','Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add',\n",
    "        'Gr Liv Area', \n",
    "        'Full Bath', 'Bedroom AbvGr',\n",
    "        'Fireplaces', 'Garage Cars']]\n",
    "\n",
    "y=smaller_df['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Train - Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Train-test splitting is a big part of the data science pipeline. The reason being, we're always trying to build models that perform well \"in the wild.\" This means that in order to evaluate our model's performance, we need to test it on data that we didn't use when building the model. This means we often want to cut out some section of our data before we do any model-building; to save for use as a \"evaluator\" of how our model performs on data it's never seen before. \n",
    "\n",
    "<img src=\"train_test_split.png\">\n",
    "\n",
    "In SkLearn, we use `train_test_split` to do this, which allows us to randomly sample the data instead of taking one big chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.809117Z",
     "start_time": "2017-12-04T20:50:04.719921Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.821892Z",
     "start_time": "2017-12-04T20:50:04.812313Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Split the data 70-30 train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.833958Z",
     "start_time": "2017-12-04T20:50:04.824617Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.844437Z",
     "start_time": "2017-12-04T20:50:04.836727Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Linear Regression\n",
    "In the first part of this notebook we will use linear regression.  We will start with a simple one-variable linear regression and then proceed to more complicated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.937810Z",
     "start_time": "2017-12-04T20:50:04.847307Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:04.945786Z",
     "start_time": "2017-12-04T20:50:04.941100Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# First let us fit only on Living Area (sqft)\n",
    "selected_columns_1 = ['Gr Liv Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Sklearn Modeling\n",
    "The package scikit-learn has a particular structure to their predictive modeling functionality.  Typically, a model is \"defined\" then it is \"fit\" (to a set of examples with their answers).  Then the trained model can be used to predict on a set of (unlabeled) data points.  We will walk through this process in the next few cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.013469Z",
     "start_time": "2017-12-04T20:50:04.949391Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## First we define a `default` LinearRegression model and fit it to the data (with just `Gr Liv Area' as a predictor\n",
    "## and SalePrice as the targer.)\n",
    "\n",
    "lr_model1 = LinearRegression()\n",
    "lr_model1.fit(X_train[selected_columns_1],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.029798Z",
     "start_time": "2017-12-04T20:50:05.017636Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Let us look at the (single) variable coefficient and the intercept\n",
    "lr_model1.coef_, lr_model1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Comprehension Question\n",
    "- What would this simple model predict as the sales price of a 1000 sq ft home?\n",
    "- Does that seem reasonable? (Remember, these are house prices in Ames, Iowa between 2006 and 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Plotting the Regression Line\n",
    "Let's use our knowledge of Matplotlib/Seaborn to make some plots of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.300850Z",
     "start_time": "2017-12-04T20:50:05.034308Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# TO DO: Make a scatterplot of the sales price (y-axis) vs the sq footage (x-axis) of the training data\n",
    "# Then, plot the regression line we just computed over the data\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X_train['Gr Liv Area'],y_train,alpha=.1)\n",
    "vec1 = np.linspace(0,4000,1000)\n",
    "plt.plot(vec1, lr_model1.intercept_ + lr_model1.coef_[0]*vec1,'r')\n",
    "plt.title(\"Housing Prices in Ames Iowa by Sq Ft (Training Set)\")\n",
    "plt.xlabel(\"Sq ft of home\")\n",
    "plt.ylabel(\"Price of home\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.561622Z",
     "start_time": "2017-12-04T20:50:05.304520Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's make a similar plot for the test set\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X_test['Gr Liv Area'],y_test,alpha=.1)\n",
    "vec1 = np.linspace(0,4000,1000)\n",
    "plt.plot(vec1, lr_model1.intercept_ + lr_model1.coef_[0]*vec1,'r')\n",
    "plt.title(\"Housing Prices in Ames Iowa by Sq Ft (Test Set)\")\n",
    "plt.xlabel(\"Sq ft of home\")\n",
    "plt.ylabel(\"Price of home\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.574917Z",
     "start_time": "2017-12-04T20:50:05.564625Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's get predictions of the model on the test set\n",
    "# Note the use of the `model.predict(feature_matrix)` syntax\n",
    "\n",
    "test_set_pred1 = lr_model1.predict(X_test[selected_columns_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:29.988210Z",
     "start_time": "2017-12-04T20:50:29.780511Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Let's plot the actual vs expected house price (along with the line x=y for reference)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(test_set_pred1,y_test,alpha=.1)\n",
    "plt.plot(np.linspace(0,600000,1000),np.linspace(0,600000,1000))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.816648Z",
     "start_time": "2017-12-04T20:50:05.806411Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# How good is our model on the test set?\n",
    "\n",
    "# Mean Squared Error\n",
    "def mean_square_error(true, pred):\n",
    "    return np.mean((pred - true)**2)\n",
    "\n",
    "mean_square_error(y_test,test_set_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:05.834712Z",
     "start_time": "2017-12-04T20:50:05.823183Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Root Mean Square Error\n",
    "def root_mean_square_error(true,pred):\n",
    "    return np.sqrt(mean_square_error(true,pred))\n",
    "\n",
    "root_mean_square_error(y_test,test_set_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:37.140042Z",
     "start_time": "2017-12-04T20:50:37.129697Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Deviation\n",
    "def mean_absolute_deviation(true,pred):\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "mean_absolute_deviation(y_test, test_set_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:37.615816Z",
     "start_time": "2017-12-04T20:50:37.600894Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# R^2\n",
    "def R2_score(true,pred):\n",
    "    y_bar_test = np.mean(true)\n",
    "    SSE = np.sum((pred - true)**2)\n",
    "    SST = np.sum((true - y_bar_test)**2)\n",
    "    return 1.-SSE/SST\n",
    "\n",
    "R2_score(y_test, test_set_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:38.265567Z",
     "start_time": "2017-12-04T20:50:38.261809Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Now let's use another variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:38.712115Z",
     "start_time": "2017-12-04T20:50:38.707407Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "selected_columns_2 = ['Lot Area', 'Overall Qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:39.421581Z",
     "start_time": "2017-12-04T20:50:39.409244Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lr_model2 = LinearRegression()\n",
    "lr_model2.fit(X_train[selected_columns_2],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:40.668619Z",
     "start_time": "2017-12-04T20:50:40.661460Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lr_model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:42.087327Z",
     "start_time": "2017-12-04T20:50:42.081752Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## This is a hack to show the variables next to their values\n",
    "list(zip(selected_columns_2,lr_model2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:43.451239Z",
     "start_time": "2017-12-04T20:50:43.445063Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_set_pred2 = lr_model2.predict(X_test[selected_columns_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:50:56.658537Z",
     "start_time": "2017-12-04T20:50:56.474560Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(test_set_pred2,y_test,alpha=.2)\n",
    "plt.plot(np.linspace(0,600000,1000),np.linspace(0,600000,1000));\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:01.383274Z",
     "start_time": "2017-12-04T20:51:01.375497Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "root_mean_square_error(y_test,test_set_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:01.650296Z",
     "start_time": "2017-12-04T20:51:01.640484Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#MAD\n",
    "mean_absolute_deviation(y_test,test_set_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:02.020682Z",
     "start_time": "2017-12-04T20:51:02.013713Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "R2_score(y_test,test_set_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Feature Engineering\n",
    "Since there seems to be some non-linearity, let's make a new variable that is \"Greater Living Area\"^2. This is called feature engineering since we're \"engineering (or making)\" a new feature out of our old features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:05.239456Z",
     "start_time": "2017-12-04T20:51:05.014951Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X['GLA2'] = X['Gr Liv Area']**2\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:05.983103Z",
     "start_time": "2017-12-04T20:51:05.976146Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## We need to recreate the train and test sets -- make sure you use the same random seed!\n",
    "#Split the data 70-30 train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:06.531000Z",
     "start_time": "2017-12-04T20:51:06.526964Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "selected_columns_3 = ['Lot Area', 'Overall Qual', 'GLA2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:06.962450Z",
     "start_time": "2017-12-04T20:51:06.950819Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lr_model3 = LinearRegression()\n",
    "lr_model3.fit(X_train[selected_columns_3],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:07.950674Z",
     "start_time": "2017-12-04T20:51:07.943000Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "list(zip(X_train[selected_columns_3].columns,lr_model3.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:08.977811Z",
     "start_time": "2017-12-04T20:51:08.972811Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_set_pred3 = lr_model3.predict(X_test[selected_columns_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:11.930276Z",
     "start_time": "2017-12-04T20:51:11.755886Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(test_set_pred3,y_test,alpha=.1)\n",
    "plt.plot(np.linspace(0,600000,1000),np.linspace(0,600000,1000));\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:14.926524Z",
     "start_time": "2017-12-04T20:51:14.919734Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#RMSE\n",
    "root_mean_square_error(y_test,test_set_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:15.155716Z",
     "start_time": "2017-12-04T20:51:15.148069Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#MAD\n",
    "mean_absolute_deviation(y_test,test_set_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-04T20:51:15.503737Z",
     "start_time": "2017-12-04T20:51:15.494575Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#R-squared\n",
    "R2_score(y_test,test_set_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "We're now going to split into groups. Each group should attempt to build the best model they can using the techniques shown above. Some recommendations:\n",
    "\n",
    "* Add some of the features we removed. But be careful, we haven't talked about how to handle categorical data, so your model won't work with categories.\n",
    "* Do some feature engineering. We played with GLA^2, but there are more variables you can try things with. You might also try multiplying some features together to see if there are \"interaction\" terms.\n",
    "* We've looked at the SkLearn Documentation, so you might also consider trying some different Regression Models - like RandomForestRegressor. Be careful though, you can't just plug-and-play some of the models into the exact same code. They don't all have coefficients for instance...\n",
    "\n",
    "Go wild. After we finish up, each group will have a chance to describe what sort of work they tried and how their model performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
